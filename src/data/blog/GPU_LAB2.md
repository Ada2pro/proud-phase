---
title: "GPU课程大作业系列"
pubDatetime: 2026-01-02T10:00:00Z
description: >
  描述我在国科大课程《GPU编程与架构》上作为旁听学生，尝试完成LAB的过程。
tags:
  - 随笔
featured: false
draft: false
timezone: "Asia/Shanghai"
---

25年9月，我作为直博生入学国科大，开学选课的时候看到了一门吸引我眼球的课程《GPU编程与架构》，因为此前的大四时期，我在导师和师兄的指导下参与了利用NVDIA GPU对后量子密码算法 Kyber 进行加速实现，期间入门了CUDA 编程，学习到了一些优化技术，但学习的深度似乎还停留于just work的层面。
后来去小红书，知乎查看这门课的评价与内容，发现相较于那种传统老旧的课而言，还挺前沿的，它至少会教你去写Triton，从底层将GPU架构到调用高级语言CUDA,Tilelang等。
对于CUDA，其还会专门用几节课的时间介绍PTX代码的编写，涵盖各种计算指令以及内存访问指令。
至于像合并内存访问，如何避免shared mem bank conflict,则是前几节课就描述清楚了......

在后面，布置了两次大作业，大作业一是优化一个脉冲神经网络算子SNN，至少要使用tiling，双缓冲，PTX优化，合并内存访问，最大限度复用寄存器等各种技术，才能有一个能满意的结果。
不过我做的时候急功近利，全让GPT-CODEX-5去写了，真正的收获很少，全关注于作业性能的排行榜了，包括后来的大作业二，这样其实对于自己知识学习和能力提升并没什么帮助......
大作业二是做一个能够在GPU领域上进行知识问答的小模型，需要做的事情有：
1. 基于PMPP、CUDA权威指南等教材制作一个优质的数据集，这里可以使用API、与大模型对话、easy dataset等方式进行制作。
2. 使用数据集对基座模型进行微调，可以用SFT或者LORA等方式，使用llama-factory进行微调。可以选择加入RAG，但速度可能变慢。
3. 使用Transformer pipeline或者vllm推理框架进行推理加速。

我其实花了很多时间在数据集制作上，调用KIMI-K2、doubao-seed-1.6、qwen3-max等国产顶级API在easy-dataset上进行数据集的提取,但是最终得到的数据集质量并不好，因此最后是使用的gpt-5.2-high进行现场生成的.......

我并不清楚SFT、LORA的原理，直接调用llama-factory的UI进行微调，各种选项询问AI进行配置。

最后踩了一些坑，比如不同的模型对话格式不同，对于qwen3-0.6b，要在微调以及后续推理的时候选择chat template为qwen3-nothink。

我发现这两天一直执着于想要上榜，想要很高的准确率和吞吐量，但事实是我是在DDL前6天才开始看，最开始做的时候连干什么都不知道，但我原本有着充足的时间去学习相关知识，这个大作业二是在11中旬就有了，但我一直没去看，说白了，我如果真的感兴趣的话，那之前在干啥呢？
我的执行力真的很匮乏，以及我对于去做大作业二的动机也很模糊。
我到底是想学习知识，还是想去让自己的排名在排行榜上靠前？
老实说。如果没有这个大作业二，我估计一直都不会去实践了解这个微调的过程，话说回来，我为什么要去学习这个微调？
对于我未来的发展有什么作用吗？
我只能将其归纳于一种业余时间时，学一点感兴趣的东西，将其固化为自己的学习技能，在未来的某个场景或许会再次用到与借鉴。

另一方面，我似乎在思考问题这个层面上分配的时间太少了，再去做一件事情的时候，我倾向于先询问GPT，而不是自己事先思考一下解决问题的可能性，比如对于微调数据集的制作上，我本可以先多花点时间思考思考：
在开源代码平台上有没有现成的高质量的数据集，制作数据集的整个流程是怎样的，前人总结的经验有哪些？数据集的大小和模型参数大小的关系？LORA微调需要的数据集和SFT所需要的数据集的区别？等等

而我现在似乎越来越缺少思考能力了，AI在给我很多便捷的同时，似乎也在慢慢侵蚀我的大脑，让其懒惰与低效，于是乎，我至少有这个博客平台供自己反思与记录。

总之，不要太看重死板的成绩排名等，在完成任务的过程中，学习到了什么新东西，如何解决遇到的问题，以及积极的和别人进行交流讨论，搜集网络上的学习资源等经历才是最重要的。



最后，给出相关课件：
Tor M. Aamodt, Wilson Wai Lun Fung, and Timothy G. Rogers. 2018. General-purpose Graphics Processor Architectures. Morgan & Claypool Publishers.


[点击下载 GPU 课程大作业课件 PDF 打包文件（2025课程大作业.zip）](/blog/GPU_pdf/课件.zip)